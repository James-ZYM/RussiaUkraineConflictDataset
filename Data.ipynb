{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "\n",
    "def get_files():\n",
    "    data_dirs = [os.path.join(\"/work/NLP examproject (293386)/NLPexam/\" , \"Comments\"), os.path.join(\"/work/NLP examproject (293386)/NLPexam/\" ,\"Submissions\")]\n",
    "    file_list = []\n",
    "    for dir in data_dirs:\n",
    "        date_dirs = os.listdir(dir)\n",
    "        \n",
    "        for subdir in date_dirs:\n",
    "            path = os.path.join(dir, subdir)\n",
    "            files = os.listdir(path)\n",
    "            \n",
    "            for file in files:\n",
    "                file_path = os.path.join(path, file)\n",
    "                file_list.append(file_path)\n",
    "    return file_list\n",
    "\n",
    "def file_to_df(file_list):\n",
    "    list = []\n",
    "    for file in file_list:\n",
    "        with open(file, 'r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            for row in reader:\n",
    "                text1 = row[14] # body\n",
    "                #text2 = row[15] # body_sha_1 \n",
    "                subreddit = row[41] # 40 for those where body = False\n",
    "                timestamp = row[47]\n",
    "                data_list = [text1, subreddit, timestamp]\n",
    "                list.append(data_list)\n",
    "                #list.append(text2)\n",
    "        data = pd.DataFrame(list)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RussiaUkraineWar2022.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    " \n",
    "test = pd.read_csv(\"/work/NLPexam/Submissions/2022-02-24/CombatFootage.csv\")\n",
    "\n",
    "\n",
    "test_com = pd.read_csv(\"/work/NLPexam/Comments/2022-02-24/CombatFootage.csv\")\n",
    "\n",
    "folder = \"/work/NLPexam/Comments/2022-02-24/\"\n",
    "files = os.listdir(folder)\n",
    "for f in files:\n",
    "    try:\n",
    "        df_temp = pd.read_csv(folder + f)\n",
    "    except Exception:\n",
    "        print(f)\n",
    "\n",
    "    \n",
    "    #print(f)\n",
    "    #df = df_temp[\"body\"]\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E: List directory /var/lib/apt/lists/partial is missing. - Acquire (13: Permission denied)\n",
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in /usr/lib/python3/dist-packages (20.3.4)\n",
      "Collecting pip\n",
      "  Using cached pip-22.3.1-py3-none-any.whl (2.1 MB)\n",
      "Collecting bertopic\n",
      "  Using cached bertopic-0.12.0-py2.py3-none-any.whl (90 kB)\n",
      "Collecting umap-learn>=0.5.0\n",
      "  Using cached umap_learn-0.5.3-py3-none-any.whl\n",
      "Collecting sentence-transformers>=0.4.1\n",
      "  Using cached sentence_transformers-2.2.2-py3-none-any.whl\n",
      "Requirement already satisfied: tqdm>=4.41.1 in /home/coder/.local/lib/python3.9/site-packages (from bertopic) (4.64.0)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2.post1 in /home/coder/.local/lib/python3.9/site-packages (from bertopic) (1.1.1)\n",
      "Collecting hdbscan>=0.8.28\n",
      "  Using cached hdbscan-0.8.29.tar.gz (5.2 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: pandas>=1.1.5 in /home/coder/.local/lib/python3.9/site-packages (from bertopic) (1.4.3)\n",
      "Collecting pyyaml<6.0\n",
      "  Using cached PyYAML-5.4.1-cp39-cp39-manylinux1_x86_64.whl (630 kB)\n",
      "Requirement already satisfied: plotly>=4.7.0 in /home/coder/.local/lib/python3.9/site-packages (from bertopic) (5.9.0)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /home/coder/.local/lib/python3.9/site-packages (from bertopic) (1.23.0)\n",
      "Requirement already satisfied: scipy>=1.0 in /home/coder/.local/lib/python3.9/site-packages (from hdbscan>=0.8.28->bertopic) (1.8.1)\n",
      "Requirement already satisfied: joblib>=1.0 in /home/coder/.local/lib/python3.9/site-packages (from hdbscan>=0.8.28->bertopic) (1.1.0)\n",
      "Collecting cython>=0.27\n",
      "  Using cached Cython-0.29.32-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (2.0 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/coder/.local/lib/python3.9/site-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/coder/.local/lib/python3.9/site-packages (from pandas>=1.1.5->bertopic) (2022.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/coder/.local/lib/python3.9/site-packages (from plotly>=4.7.0->bertopic) (8.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/coder/.local/lib/python3.9/site-packages (from scikit-learn>=0.22.2.post1->bertopic) (3.1.0)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.14.0-cp39-cp39-manylinux1_x86_64.whl (24.3 MB)\n",
      "Collecting sentencepiece\n",
      "  Using cached sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Collecting transformers<5.0.0,>=4.6.0\n",
      "  Using cached transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
      "Collecting huggingface-hub>=0.4.0\n",
      "  Using cached huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
      "Collecting nltk\n",
      "  Using cached nltk-3.7-py3-none-any.whl (1.5 MB)\n",
      "Collecting torch>=1.6.0\n",
      "  Using cached torch-1.13.0-cp39-cp39-manylinux1_x86_64.whl (890.2 MB)\n",
      "Collecting numba>=0.49\n",
      "  Using cached numba-0.56.4-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)\n",
      "Collecting pynndescent>=0.5\n",
      "  Using cached pynndescent-0.5.8-py3-none-any.whl\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.8.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: requests in /home/coder/.local/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2.28.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/coder/.local/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (4.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/coder/.local/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (21.3)\n",
      "Requirement already satisfied: setuptools in /home/coder/.local/lib/python3.9/site-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic) (65.6.3)\n",
      "Collecting llvmlite<0.40,>=0.39.0dev0\n",
      "  Using cached llvmlite-0.39.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.6 MB)\n",
      "Requirement already satisfied: six>=1.5 in /home/coder/.local/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas>=1.1.5->bertopic) (1.16.0)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "Requirement already satisfied: wheel in /home/coder/.local/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (0.38.4)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2022.10.31-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (769 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Using cached tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "Requirement already satisfied: click in /home/coder/.local/lib/python3.9/site-packages (from nltk->sentence-transformers>=0.4.1->bertopic) (8.1.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/coder/.local/lib/python3.9/site-packages (from torchvision->sentence-transformers>=0.4.1->bertopic) (9.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/coder/.local/lib/python3.9/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/coder/.local/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/coder/.local/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/coder/.local/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/coder/.local/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2.1.0)\n",
      "Building wheels for collected packages: hdbscan\n",
      "  Building wheel for hdbscan (pyproject.toml): started\n",
      "  Building wheel for hdbscan (pyproject.toml): finished with status 'error'\n",
      "Failed to build hdbscan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Building wheel for hdbscan (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [47 lines of output]\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\n",
      "      creating build/lib.linux-x86_64-cpython-39\n",
      "      creating build/lib.linux-x86_64-cpython-39/hdbscan\n",
      "      copying hdbscan/__init__.py -> build/lib.linux-x86_64-cpython-39/hdbscan\n",
      "      copying hdbscan/flat.py -> build/lib.linux-x86_64-cpython-39/hdbscan\n",
      "      copying hdbscan/hdbscan_.py -> build/lib.linux-x86_64-cpython-39/hdbscan\n",
      "      copying hdbscan/plots.py -> build/lib.linux-x86_64-cpython-39/hdbscan\n",
      "      copying hdbscan/prediction.py -> build/lib.linux-x86_64-cpython-39/hdbscan\n",
      "      copying hdbscan/robust_single_linkage_.py -> build/lib.linux-x86_64-cpython-39/hdbscan\n",
      "      copying hdbscan/validity.py -> build/lib.linux-x86_64-cpython-39/hdbscan\n",
      "      creating build/lib.linux-x86_64-cpython-39/hdbscan/tests\n",
      "      copying hdbscan/tests/__init__.py -> build/lib.linux-x86_64-cpython-39/hdbscan/tests\n",
      "      copying hdbscan/tests/test_flat.py -> build/lib.linux-x86_64-cpython-39/hdbscan/tests\n",
      "      copying hdbscan/tests/test_hdbscan.py -> build/lib.linux-x86_64-cpython-39/hdbscan/tests\n",
      "      copying hdbscan/tests/test_prediction_utils.py -> build/lib.linux-x86_64-cpython-39/hdbscan/tests\n",
      "      copying hdbscan/tests/test_rsl.py -> build/lib.linux-x86_64-cpython-39/hdbscan/tests\n",
      "      running build_ext\n",
      "      cythoning hdbscan/_hdbscan_tree.pyx to hdbscan/_hdbscan_tree.c\n",
      "      /tmp/pip-build-env-hrgvp3w_/overlay/lib/python3.9/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /tmp/pip-install-y_6_nlzx/hdbscan_671a93aefef340e5882d49f6766f3be4/hdbscan/_hdbscan_tree.pyx\n",
      "        tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "      cythoning hdbscan/_hdbscan_linkage.pyx to hdbscan/_hdbscan_linkage.c\n",
      "      /tmp/pip-build-env-hrgvp3w_/overlay/lib/python3.9/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /tmp/pip-install-y_6_nlzx/hdbscan_671a93aefef340e5882d49f6766f3be4/hdbscan/_hdbscan_linkage.pyx\n",
      "        tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "      cythoning hdbscan/_hdbscan_boruvka.pyx to hdbscan/_hdbscan_boruvka.c\n",
      "      /tmp/pip-build-env-hrgvp3w_/overlay/lib/python3.9/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /tmp/pip-install-y_6_nlzx/hdbscan_671a93aefef340e5882d49f6766f3be4/hdbscan/_hdbscan_boruvka.pyx\n",
      "        tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "      cythoning hdbscan/_hdbscan_reachability.pyx to hdbscan/_hdbscan_reachability.c\n",
      "      /tmp/pip-build-env-hrgvp3w_/overlay/lib/python3.9/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /tmp/pip-install-y_6_nlzx/hdbscan_671a93aefef340e5882d49f6766f3be4/hdbscan/_hdbscan_reachability.pyx\n",
      "        tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "      cythoning hdbscan/_prediction_utils.pyx to hdbscan/_prediction_utils.c\n",
      "      /tmp/pip-build-env-hrgvp3w_/overlay/lib/python3.9/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /tmp/pip-install-y_6_nlzx/hdbscan_671a93aefef340e5882d49f6766f3be4/hdbscan/_prediction_utils.pyx\n",
      "        tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "      cythoning hdbscan/dist_metrics.pyx to hdbscan/dist_metrics.c\n",
      "      /tmp/pip-build-env-hrgvp3w_/overlay/lib/python3.9/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /tmp/pip-install-y_6_nlzx/hdbscan_671a93aefef340e5882d49f6766f3be4/hdbscan/dist_metrics.pxd\n",
      "        tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "      building 'hdbscan._hdbscan_tree' extension\n",
      "      creating build/temp.linux-x86_64-cpython-39\n",
      "      creating build/temp.linux-x86_64-cpython-39/hdbscan\n",
      "      x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -ffile-prefix-map=/build/python3.9-RNBry6/python3.9-3.9.2=. -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/include/python3.9 -I/tmp/pip-build-env-hrgvp3w_/overlay/lib/python3.9/site-packages/numpy/core/include -c hdbscan/_hdbscan_tree.c -o build/temp.linux-x86_64-cpython-39/hdbscan/_hdbscan_tree.o\n",
      "      hdbscan/_hdbscan_tree.c:6:10: fatal error: Python.h: No such file or directory\n",
      "          6 | #include \"Python.h\"\n",
      "            |          ^~~~~~~~~~\n",
      "      compilation terminated.\n",
      "      error: command '/usr/bin/x86_64-linux-gnu-gcc' failed with exit code 1\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for hdbscan\n",
      "ERROR: Could not build wheels for hdbscan, which is required to install pyproject.toml-based projects\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bertopic'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/work/NLP examproject (293386)/NLPexam/Data.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://app-299402-0.cloud.sdu.dk/work/NLP%20examproject%20%28293386%29/NLPexam/Data.ipynb#ch0000001vscode-remote?line=1'>2</a>\u001b[0m os\u001b[39m.\u001b[39msystem(\u001b[39m'\u001b[39m\u001b[39m apt-get install -y build-essential\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://app-299402-0.cloud.sdu.dk/work/NLP%20examproject%20%28293386%29/NLPexam/Data.ipynb#ch0000001vscode-remote?line=2'>3</a>\u001b[0m os\u001b[39m.\u001b[39msystem(\u001b[39m'\u001b[39m\u001b[39mpip install --upgrade pip bertopic\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://app-299402-0.cloud.sdu.dk/work/NLP%20examproject%20%28293386%29/NLPexam/Data.ipynb#ch0000001vscode-remote?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbertopic\u001b[39;00m \u001b[39mimport\u001b[39;00m BERTopic\n\u001b[1;32m      <a href='vscode-notebook-cell://app-299402-0.cloud.sdu.dk/work/NLP%20examproject%20%28293386%29/NLPexam/Data.ipynb#ch0000001vscode-remote?line=5'>6</a>\u001b[0m topic_model \u001b[39m=\u001b[39m BERTopic()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bertopic'"
     ]
    }
   ],
   "source": [
    "#Kathrines kode\n",
    "os.system('apt-get update')\n",
    "os.system('apt-get install -y build-essential')\n",
    "os.system('pip install --upgrade pip bertopic')\n",
    "from bertopic import BERTopic\n",
    "\n",
    "topic_model = BERTopic()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>all_awardings</th>\n",
       "      <th>archived</th>\n",
       "      <th>associated_award</th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_background_color</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_richtext</th>\n",
       "      <th>author_flair_template_id</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>...</th>\n",
       "      <th>subreddit_type</th>\n",
       "      <th>top_awarded_type</th>\n",
       "      <th>total_awards_received</th>\n",
       "      <th>treatment_tags</th>\n",
       "      <th>unrepliable_reason</th>\n",
       "      <th>created</th>\n",
       "      <th>author_cakeday</th>\n",
       "      <th>awarders</th>\n",
       "      <th>retrieved_on</th>\n",
       "      <th>edited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rysky15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>public</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.645718e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RetardStockBot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>public</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.645718e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PVKT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>public</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.645718e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>omegazx00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>public</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.645718e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KyogreHype</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>public</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.645718e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40825</th>\n",
       "      <td>40825</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lonely_Key4375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.645632e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.652896e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40826</th>\n",
       "      <td>40826</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>_ThatAltAcc_</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.645632e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.652896e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40827</th>\n",
       "      <td>40827</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TitVanSprinkle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.645632e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.652894e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40828</th>\n",
       "      <td>40828</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>billyballzdeep</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.645632e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.652894e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40829</th>\n",
       "      <td>40829</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.645632e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.652894e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40830 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0 all_awardings archived  associated_award          author  \\\n",
       "0               0            []    False               NaN         Rysky15   \n",
       "1               1            []    False               NaN  RetardStockBot   \n",
       "2               2            []    False               NaN            PVKT   \n",
       "3               3            []    False               NaN       omegazx00   \n",
       "4               4            []    False               NaN      KyogreHype   \n",
       "...           ...           ...      ...               ...             ...   \n",
       "40825       40825            []      NaN               NaN  Lonely_Key4375   \n",
       "40826       40826            []      NaN               NaN    _ThatAltAcc_   \n",
       "40827       40827            []      NaN               NaN  TitVanSprinkle   \n",
       "40828       40828            []      NaN               NaN  billyballzdeep   \n",
       "40829       40829            []      NaN               NaN   AutoModerator   \n",
       "\n",
       "       author_flair_background_color author_flair_css_class  \\\n",
       "0                                NaN                    NaN   \n",
       "1                                NaN                    NaN   \n",
       "2                                NaN                    NaN   \n",
       "3                                NaN                    NaN   \n",
       "4                                NaN                    NaN   \n",
       "...                              ...                    ...   \n",
       "40825                            NaN                    NaN   \n",
       "40826                            NaN                    NaN   \n",
       "40827                            NaN                    NaN   \n",
       "40828                            NaN                    NaN   \n",
       "40829                            NaN                    NaN   \n",
       "\n",
       "      author_flair_richtext author_flair_template_id author_flair_text  ...  \\\n",
       "0                        []                      NaN               NaN  ...   \n",
       "1                        []                      NaN               NaN  ...   \n",
       "2                        []                      NaN               NaN  ...   \n",
       "3                        []                      NaN               NaN  ...   \n",
       "4                        []                      NaN               NaN  ...   \n",
       "...                     ...                      ...               ...  ...   \n",
       "40825                    []                      NaN               NaN  ...   \n",
       "40826                    []                      NaN               NaN  ...   \n",
       "40827                    []                      NaN               NaN  ...   \n",
       "40828                    []                      NaN               NaN  ...   \n",
       "40829                    []                      NaN               NaN  ...   \n",
       "\n",
       "      subreddit_type top_awarded_type total_awards_received treatment_tags  \\\n",
       "0             public              NaN                     0             []   \n",
       "1             public              NaN                     0             []   \n",
       "2             public              NaN                     0             []   \n",
       "3             public              NaN                     0             []   \n",
       "4             public              NaN                     0             []   \n",
       "...              ...              ...                   ...            ...   \n",
       "40825            NaN              NaN                     0             []   \n",
       "40826            NaN              NaN                     0             []   \n",
       "40827            NaN              NaN                     0             []   \n",
       "40828            NaN              NaN                     0             []   \n",
       "40829            NaN              NaN                     0             []   \n",
       "\n",
       "      unrepliable_reason       created author_cakeday awarders  retrieved_on  \\\n",
       "0                    NaN  1.645718e+09            NaN      NaN           NaN   \n",
       "1                    NaN  1.645718e+09            NaN      NaN           NaN   \n",
       "2                    NaN  1.645718e+09            NaN      NaN           NaN   \n",
       "3                    NaN  1.645718e+09            NaN      NaN           NaN   \n",
       "4                    NaN  1.645718e+09            NaN      NaN           NaN   \n",
       "...                  ...           ...            ...      ...           ...   \n",
       "40825                NaN  1.645632e+09            NaN       []  1.652896e+09   \n",
       "40826                NaN  1.645632e+09            NaN       []  1.652896e+09   \n",
       "40827                NaN  1.645632e+09            NaN       []  1.652894e+09   \n",
       "40828                NaN  1.645632e+09            NaN       []  1.652894e+09   \n",
       "40829                NaN  1.645632e+09            NaN       []  1.652894e+09   \n",
       "\n",
       "       edited  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  \n",
       "...       ...  \n",
       "40825     NaN  \n",
       "40826     NaN  \n",
       "40827     NaN  \n",
       "40828     NaN  \n",
       "40829     NaN  \n",
       "\n",
       "[40830 rows x 53 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "\n",
    "test_com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(\"Python Program to print list the files in a directory.\")\n",
    " \n",
    "Direc = input(r\"Enter the path of the folder: \")\n",
    "print(f\"Files in the directory: {Direc}\")\n",
    " \n",
    "files = os.listdir(Direc)\n",
    "files = [f for f in files if os.path.isfile(Direc+'/'+f)] \n",
    "print(*files, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bertopic'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/work/NLPexam/Data.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://app-293386-0.cloud.sdu.dk/work/NLPexam/Data.ipynb#ch0000000vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbertopic\u001b[39;00m \u001b[39mimport\u001b[39;00m BERTopic\n\u001b[1;32m      <a href='vscode-notebook-cell://app-293386-0.cloud.sdu.dk/work/NLPexam/Data.ipynb#ch0000000vscode-remote?line=2'>3</a>\u001b[0m topic_model \u001b[39m=\u001b[39m BERTopic()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bertopic'"
     ]
    }
   ],
   "source": [
    "from bertopic import BERTopic\n",
    "\n",
    "topic_model = BERTopic()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
