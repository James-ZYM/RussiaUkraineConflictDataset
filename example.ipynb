{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Prepare data\n",
    "trump = pd.read_csv('https://drive.google.com/uc?export=download&id=1xRKHaP-QwACMydlDnyFPEaFdtskJuBa6')\n",
    "trump.text = trump.apply(lambda row: re.sub(r\"http\\S+\", \"\", row.text).lower(), 1)\n",
    "trump.text = trump.apply(lambda row: \" \".join(filter(lambda x:x[0]!=\"@\", row.text.split())), 1)\n",
    "trump.text = trump.apply(lambda row: \" \".join(re.sub(\"[^a-zA-Z]+\", \" \", row.text).split()), 1)\n",
    "trump = trump.loc[(trump.isRetweet == \"f\") & (trump.text != \"\"), :]\n",
    "timestamps = trump.date.to_list()\n",
    "tweets = trump.text.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45355\n",
      "45355\n"
     ]
    }
   ],
   "source": [
    "print(len(timestamps))\n",
    "print(len(tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E: List directory /var/lib/apt/lists/partial is missing. - Acquire (13: Permission denied)\n",
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in /usr/lib/python3/dist-packages (20.3.4)\n",
      "Collecting pip\n",
      "  Using cached pip-22.3.1-py3-none-any.whl (2.1 MB)\n",
      "Collecting bertopic\n",
      "  Using cached bertopic-0.12.0-py2.py3-none-any.whl (90 kB)\n",
      "Requirement already satisfied: tqdm>=4.41.1 in /home/coder/.local/lib/python3.9/site-packages (from bertopic) (4.64.0)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /home/coder/.local/lib/python3.9/site-packages (from bertopic) (1.23.0)\n",
      "Collecting pyyaml<6.0\n",
      "  Using cached PyYAML-5.4.1-cp39-cp39-manylinux1_x86_64.whl (630 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2.post1 in /home/coder/.local/lib/python3.9/site-packages (from bertopic) (1.1.1)\n",
      "Collecting sentence-transformers>=0.4.1\n",
      "  Using cached sentence_transformers-2.2.2-py3-none-any.whl\n",
      "Requirement already satisfied: pandas>=1.1.5 in /home/coder/.local/lib/python3.9/site-packages (from bertopic) (1.4.3)\n",
      "Collecting hdbscan>=0.8.28\n",
      "  Using cached hdbscan-0.8.29.tar.gz (5.2 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: plotly>=4.7.0 in /home/coder/.local/lib/python3.9/site-packages (from bertopic) (5.9.0)\n",
      "Collecting umap-learn>=0.5.0\n",
      "  Using cached umap_learn-0.5.3-py3-none-any.whl\n",
      "Requirement already satisfied: joblib>=1.0 in /home/coder/.local/lib/python3.9/site-packages (from hdbscan>=0.8.28->bertopic) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.0 in /home/coder/.local/lib/python3.9/site-packages (from hdbscan>=0.8.28->bertopic) (1.8.1)\n",
      "Collecting cython>=0.27\n",
      "  Using cached Cython-0.29.32-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (2.0 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/coder/.local/lib/python3.9/site-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/coder/.local/lib/python3.9/site-packages (from pandas>=1.1.5->bertopic) (2022.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/coder/.local/lib/python3.9/site-packages (from plotly>=4.7.0->bertopic) (8.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/coder/.local/lib/python3.9/site-packages (from scikit-learn>=0.22.2.post1->bertopic) (3.1.0)\n",
      "Collecting huggingface-hub>=0.4.0\n",
      "  Using cached huggingface_hub-0.11.0-py3-none-any.whl (182 kB)\n",
      "Collecting sentencepiece\n",
      "  Using cached sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Collecting torch>=1.6.0\n",
      "  Using cached torch-1.13.0-cp39-cp39-manylinux1_x86_64.whl (890.2 MB)\n",
      "Collecting transformers<5.0.0,>=4.6.0\n",
      "  Using cached transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
      "Collecting nltk\n",
      "  Using cached nltk-3.7-py3-none-any.whl (1.5 MB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.14.0-cp39-cp39-manylinux1_x86_64.whl (24.3 MB)\n",
      "Collecting pynndescent>=0.5\n",
      "  Using cached pynndescent-0.5.8-py3-none-any.whl\n",
      "Collecting numba>=0.49\n",
      "  Using cached numba-0.56.4-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/coder/.local/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (21.3)\n",
      "Requirement already satisfied: requests in /home/coder/.local/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2.28.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/coder/.local/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (4.3.0)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.8.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic) (52.0.0)\n",
      "Collecting llvmlite<0.40,>=0.39.0dev0\n",
      "  Using cached llvmlite-0.39.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.6 MB)\n",
      "Requirement already satisfied: six>=1.5 in /home/coder/.local/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas>=1.1.5->bertopic) (1.16.0)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (0.34.2)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2022.10.31-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (769 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Using cached tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "Requirement already satisfied: click in /home/coder/.local/lib/python3.9/site-packages (from nltk->sentence-transformers>=0.4.1->bertopic) (8.1.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/coder/.local/lib/python3.9/site-packages (from torchvision->sentence-transformers>=0.4.1->bertopic) (9.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/coder/.local/lib/python3.9/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/coder/.local/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/coder/.local/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/coder/.local/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/coder/.local/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2022.6.15)\n",
      "Building wheels for collected packages: hdbscan\n",
      "  Building wheel for hdbscan (pyproject.toml): started\n",
      "  Building wheel for hdbscan (pyproject.toml): finished with status 'error'\n",
      "Failed to build hdbscan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Building wheel for hdbscan (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [47 lines of output]\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\n",
      "      creating build/lib.linux-x86_64-cpython-39\n",
      "      creating build/lib.linux-x86_64-cpython-39/hdbscan\n",
      "      copying hdbscan/__init__.py -> build/lib.linux-x86_64-cpython-39/hdbscan\n",
      "      copying hdbscan/flat.py -> build/lib.linux-x86_64-cpython-39/hdbscan\n",
      "      copying hdbscan/hdbscan_.py -> build/lib.linux-x86_64-cpython-39/hdbscan\n",
      "      copying hdbscan/plots.py -> build/lib.linux-x86_64-cpython-39/hdbscan\n",
      "      copying hdbscan/prediction.py -> build/lib.linux-x86_64-cpython-39/hdbscan\n",
      "      copying hdbscan/robust_single_linkage_.py -> build/lib.linux-x86_64-cpython-39/hdbscan\n",
      "      copying hdbscan/validity.py -> build/lib.linux-x86_64-cpython-39/hdbscan\n",
      "      creating build/lib.linux-x86_64-cpython-39/hdbscan/tests\n",
      "      copying hdbscan/tests/__init__.py -> build/lib.linux-x86_64-cpython-39/hdbscan/tests\n",
      "      copying hdbscan/tests/test_flat.py -> build/lib.linux-x86_64-cpython-39/hdbscan/tests\n",
      "      copying hdbscan/tests/test_hdbscan.py -> build/lib.linux-x86_64-cpython-39/hdbscan/tests\n",
      "      copying hdbscan/tests/test_prediction_utils.py -> build/lib.linux-x86_64-cpython-39/hdbscan/tests\n",
      "      copying hdbscan/tests/test_rsl.py -> build/lib.linux-x86_64-cpython-39/hdbscan/tests\n",
      "      running build_ext\n",
      "      cythoning hdbscan/_hdbscan_tree.pyx to hdbscan/_hdbscan_tree.c\n",
      "      /tmp/pip-build-env-vqsla_vv/overlay/lib/python3.9/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /tmp/pip-install-08si9ao5/hdbscan_be24ecf3a38e44968c15fa4348f767ec/hdbscan/_hdbscan_tree.pyx\n",
      "        tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "      cythoning hdbscan/_hdbscan_linkage.pyx to hdbscan/_hdbscan_linkage.c\n",
      "      /tmp/pip-build-env-vqsla_vv/overlay/lib/python3.9/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /tmp/pip-install-08si9ao5/hdbscan_be24ecf3a38e44968c15fa4348f767ec/hdbscan/_hdbscan_linkage.pyx\n",
      "        tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "      cythoning hdbscan/_hdbscan_boruvka.pyx to hdbscan/_hdbscan_boruvka.c\n",
      "      /tmp/pip-build-env-vqsla_vv/overlay/lib/python3.9/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /tmp/pip-install-08si9ao5/hdbscan_be24ecf3a38e44968c15fa4348f767ec/hdbscan/_hdbscan_boruvka.pyx\n",
      "        tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "      cythoning hdbscan/_hdbscan_reachability.pyx to hdbscan/_hdbscan_reachability.c\n",
      "      /tmp/pip-build-env-vqsla_vv/overlay/lib/python3.9/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /tmp/pip-install-08si9ao5/hdbscan_be24ecf3a38e44968c15fa4348f767ec/hdbscan/_hdbscan_reachability.pyx\n",
      "        tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "      cythoning hdbscan/_prediction_utils.pyx to hdbscan/_prediction_utils.c\n",
      "      /tmp/pip-build-env-vqsla_vv/overlay/lib/python3.9/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /tmp/pip-install-08si9ao5/hdbscan_be24ecf3a38e44968c15fa4348f767ec/hdbscan/_prediction_utils.pyx\n",
      "        tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "      cythoning hdbscan/dist_metrics.pyx to hdbscan/dist_metrics.c\n",
      "      /tmp/pip-build-env-vqsla_vv/overlay/lib/python3.9/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /tmp/pip-install-08si9ao5/hdbscan_be24ecf3a38e44968c15fa4348f767ec/hdbscan/dist_metrics.pxd\n",
      "        tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "      building 'hdbscan._hdbscan_tree' extension\n",
      "      creating build/temp.linux-x86_64-cpython-39\n",
      "      creating build/temp.linux-x86_64-cpython-39/hdbscan\n",
      "      x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -ffile-prefix-map=/build/python3.9-RNBry6/python3.9-3.9.2=. -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/include/python3.9 -I/tmp/pip-build-env-vqsla_vv/overlay/lib/python3.9/site-packages/numpy/core/include -c hdbscan/_hdbscan_tree.c -o build/temp.linux-x86_64-cpython-39/hdbscan/_hdbscan_tree.o\n",
      "      hdbscan/_hdbscan_tree.c:6:10: fatal error: Python.h: No such file or directory\n",
      "          6 | #include \"Python.h\"\n",
      "            |          ^~~~~~~~~~\n",
      "      compilation terminated.\n",
      "      error: command '/usr/bin/x86_64-linux-gnu-gcc' failed with exit code 1\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for hdbscan\n",
      "ERROR: Could not build wheels for hdbscan, which is required to install pyproject.toml-based projects\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bertopic'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/work/NLP - classrooms/github/NLP-AU/NLPexam/example.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://app-296589-0.cloud.sdu.dk/work/NLP%20-%20classrooms/github/NLP-AU/NLPexam/example.ipynb#ch0000002vscode-remote?line=1'>2</a>\u001b[0m os\u001b[39m.\u001b[39msystem(\u001b[39m'\u001b[39m\u001b[39m apt-get install -y build-essential\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://app-296589-0.cloud.sdu.dk/work/NLP%20-%20classrooms/github/NLP-AU/NLPexam/example.ipynb#ch0000002vscode-remote?line=2'>3</a>\u001b[0m os\u001b[39m.\u001b[39msystem(\u001b[39m'\u001b[39m\u001b[39mpip install --upgrade pip bertopic\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://app-296589-0.cloud.sdu.dk/work/NLP%20-%20classrooms/github/NLP-AU/NLPexam/example.ipynb#ch0000002vscode-remote?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbertopic\u001b[39;00m \u001b[39mimport\u001b[39;00m BERTopic\n\u001b[1;32m      <a href='vscode-notebook-cell://app-296589-0.cloud.sdu.dk/work/NLP%20-%20classrooms/github/NLP-AU/NLPexam/example.ipynb#ch0000002vscode-remote?line=5'>6</a>\u001b[0m topic_model \u001b[39m=\u001b[39m BERTopic(verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://app-296589-0.cloud.sdu.dk/work/NLP%20-%20classrooms/github/NLP-AU/NLPexam/example.ipynb#ch0000002vscode-remote?line=6'>7</a>\u001b[0m topics, probs \u001b[39m=\u001b[39m topic_model\u001b[39m.\u001b[39mfit_transform(tweets)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bertopic'"
     ]
    }
   ],
   "source": [
    "\n",
    "os.system('apt-get update')\n",
    "os.system(' apt-get install -y build-essential')\n",
    "os.system('pip install --upgrade pip bertopic')\n",
    "from bertopic import BERTopic\n",
    "\n",
    "topic_model = BERTopic(verbose=True)\n",
    "topics, probs = topic_model.fit_transform(tweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bertopic'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/work/NLP - classrooms/github/NLP-AU/NLPexam/example.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://app-296589-0.cloud.sdu.dk/work/NLP%20-%20classrooms/github/NLP-AU/NLPexam/example.ipynb#ch0000003vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mbertopic\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bertopic'"
     ]
    }
   ],
   "source": [
    "import bertopic"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
